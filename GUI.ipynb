{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec1459-26a0-484e-b98b-dbeb2dce145c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-loaded model from outputs\\best_brain_tumor_model.pth\n",
      "Opened image: C:/Users/ACER/OneDrive/Desktop/archive (3)/Testing/meningioma/Te-me_0011.jpg size: (200, 223) mode: RGB\n"
     ]
    }
   ],
   "source": [
    "# brain_tumor_gui_notebook.py\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "\n",
    "from PyQt5.QtWidgets import (\n",
    "    QApplication, QMainWindow, QLabel, QPushButton, QFileDialog,\n",
    "    QVBoxLayout, QWidget, QHBoxLayout, QListWidget, QListWidgetItem, QMessageBox\n",
    ")\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "from PyQt5.QtCore import Qt, QTimer\n",
    "\n",
    "# USER CONFIG \n",
    "ARCHIVE_DEFAULT = Path(r\"C:\\Users\\ACER\\Desktop\\archive (3)\")\n",
    "DEFAULT_MODEL_NAMES = [\n",
    "    ARCHIVE_DEFAULT / \"trained_brain_tumor_model.h5\",\n",
    "    Path(\"outputs\") / \"best_brain_tumor_model.pth\"\n",
    "]\n",
    "IMAGE_SIZE = 224\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD  = [0.229, 0.224, 0.225]\n",
    "DEFAULT_CLASS_NAMES = ['glioma', 'meningioma', 'pituitary', 'notumor']\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(int(IMAGE_SIZE * 1.14)),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "def pil_image_to_qpixmap(pil_image, max_size=(520,520)):\n",
    "    \"\"\"Convert PIL->QPixmap robustly using numpy -> QImage.\"\"\"\n",
    "    if pil_image is None:\n",
    "        return None\n",
    "    # ensure PIL mode\n",
    "    try:\n",
    "        mode = pil_image.mode\n",
    "    except Exception:\n",
    "        pil_image = pil_image.convert('RGB')\n",
    "        mode = 'RGB'\n",
    "    if mode not in ('RGB', 'L'):\n",
    "        try:\n",
    "            pil_image = pil_image.convert('RGB')\n",
    "            mode = 'RGB'\n",
    "        except Exception:\n",
    "            pil_image = pil_image.convert('L')\n",
    "            mode = 'L'\n",
    "\n",
    "    # resize\n",
    "    w,h = pil_image.size\n",
    "    max_w, max_h = max_size\n",
    "    scale = min(max_w/w, max_h/h, 1.0)\n",
    "    new_w, new_h = int(w*scale), int(h*scale)\n",
    "    if (new_w,new_h) != (w,h):\n",
    "        try:\n",
    "            pil_image = pil_image.resize((new_w,new_h), Image.LANCZOS)\n",
    "        except Exception:\n",
    "            pil_image = pil_image.resize((new_w,new_h), Image.ANTIALIAS)\n",
    "\n",
    "    arr = np.ascontiguousarray(np.asarray(pil_image))\n",
    "    if arr.dtype != np.uint8:\n",
    "        arr = (255 * (arr / np.max(arr))).astype(np.uint8)\n",
    "\n",
    "    try:\n",
    "        if arr.ndim == 2:\n",
    "            height, width = arr.shape\n",
    "            bytes_per_line = width\n",
    "            qimg = QImage(arr.data, width, height, bytes_per_line, QImage.Format_Grayscale8)\n",
    "        elif arr.shape[2] == 3:\n",
    "            height, width, _ = arr.shape\n",
    "            bytes_per_line = 3 * width\n",
    "            qimg = QImage(arr.data, width, height, bytes_per_line, QImage.Format_RGB888)\n",
    "        elif arr.shape[2] == 4:\n",
    "            arr = arr[:, :, :3]\n",
    "            height, width, _ = arr.shape\n",
    "            bytes_per_line = 3 * width\n",
    "            qimg = QImage(arr.data, width, height, bytes_per_line, QImage.Format_RGB888)\n",
    "        else:\n",
    "            return None\n",
    "        return QPixmap.fromImage(qimg)\n",
    "    except Exception as e:\n",
    "        # fallback conversion\n",
    "        try:\n",
    "            pil2 = pil_image.convert('RGB')\n",
    "            arr2 = np.ascontiguousarray(np.asarray(pil2))\n",
    "            h2,w2,_ = arr2.shape\n",
    "            qimg = QImage(arr2.data, w2, h2, 3*w2, QImage.Format_RGB888)\n",
    "            return QPixmap.fromImage(qimg)\n",
    "        except Exception:\n",
    "            print(\"pil->qpixmap failed:\", e)\n",
    "            return None\n",
    "\n",
    "class ModelLoader:\n",
    "    \"\"\"Load full saved model objects or checkpoint dicts with state_dict + classes.\"\"\"\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.model = None\n",
    "        self.classes = DEFAULT_CLASS_NAMES\n",
    "\n",
    "    def infer_backbone_from_state_dict(self, state_dict):\n",
    "        keys = list(state_dict.keys())\n",
    "        if any('layer1' in k or 'layer2' in k for k in keys) or any('fc.' in k for k in keys):\n",
    "            return 'resnet'\n",
    "        if any('features' in k or 'classifier' in k for k in keys):\n",
    "            return 'efficientnet'\n",
    "        return 'resnet'\n",
    "\n",
    "    def build_model_for_state_dict(self, state_dict, num_classes):\n",
    "        backbone = self.infer_backbone_from_state_dict(state_dict)\n",
    "        if backbone == 'resnet':\n",
    "            from torchvision.models import ResNet50_Weights\n",
    "            model = models.resnet50(weights=None)\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = torch.nn.Linear(in_features, num_classes)\n",
    "            return model\n",
    "        elif backbone == 'efficientnet':\n",
    "            from torchvision.models import EfficientNet_B0_Weights\n",
    "            model = models.efficientnet_b0(weights=None)\n",
    "            in_features = model.classifier[1].in_features\n",
    "            model.classifier[1] = torch.nn.Linear(in_features, num_classes)\n",
    "            return model\n",
    "        else:\n",
    "            from torchvision.models import ResNet50_Weights\n",
    "            model = models.resnet50(weights=None)\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = torch.nn.Linear(in_features, num_classes)\n",
    "            return model\n",
    "\n",
    "    def load(self, path):\n",
    "        path = Path(path)\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Model file not found: {path}\")\n",
    "        loaded = torch.load(str(path), map_location=self.device)\n",
    "        # full model object\n",
    "        if isinstance(loaded, torch.nn.Module):\n",
    "            self.model = loaded.to(self.device)\n",
    "            self.model.eval()\n",
    "            return\n",
    "        # checkpoint-like dict\n",
    "        if isinstance(loaded, dict):\n",
    "            if 'classes' in loaded and isinstance(loaded['classes'], (list,tuple)):\n",
    "                self.classes = list(loaded['classes'])\n",
    "            state = None\n",
    "            for key in ('model_state', 'model_state_dict', 'state_dict', 'model'):\n",
    "                if key in loaded:\n",
    "                    state = loaded[key]; break\n",
    "            if state is None:\n",
    "                state = loaded\n",
    "            if isinstance(state, dict):\n",
    "                num_classes = len(self.classes) if self.classes else len(DEFAULT_CLASS_NAMES)\n",
    "                model = self.build_model_for_state_dict(state, num_classes)\n",
    "                model.load_state_dict(state)\n",
    "                self.model = model.to(self.device)\n",
    "                self.model.eval()\n",
    "                return\n",
    "        raise RuntimeError(\"Unsupported model file format. Save with torch.save(model) or torch.save({'model_state': model.state_dict(), 'classes': [...]})\")\n",
    "\n",
    "    def predict(self, pil_image):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not loaded\")\n",
    "        img = val_transform(pil_image).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(img)\n",
    "            probs = F.softmax(outputs, dim=1).cpu().numpy()[0]\n",
    "        return probs\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"Brain Tumor Classifier (Notebook)\")\n",
    "        self.resize(920,620)\n",
    "\n",
    "        self.model_loader = ModelLoader(device)\n",
    "\n",
    "        # widgets\n",
    "        self.image_label = QLabel(\"No image loaded\")\n",
    "        self.image_label.setAlignment(Qt.AlignCenter)\n",
    "        self.image_label.setFixedSize(520,520)\n",
    "        self.image_label.setStyleSheet(\"border:1px solid gray;\")\n",
    "\n",
    "        self.pred_label = QLabel(\"Model: not loaded\")\n",
    "        self.pred_label.setWordWrap(True)\n",
    "        self.pred_label.setAlignment(Qt.AlignLeft)\n",
    "\n",
    "        self.load_model_btn = QPushButton(\"Load Model\")\n",
    "        self.load_model_btn.clicked.connect(self.load_model)\n",
    "\n",
    "        self.load_image_btn = QPushButton(\"Load Image\")\n",
    "        self.load_image_btn.clicked.connect(self.load_image)\n",
    "\n",
    "        self.predict_btn = QPushButton(\"Predict\")\n",
    "        self.predict_btn.clicked.connect(self.run_prediction)\n",
    "        self.predict_btn.setEnabled(False)\n",
    "\n",
    "        self.prob_list = QListWidget()\n",
    "\n",
    "        # layouts\n",
    "        left = QVBoxLayout()\n",
    "        left.addWidget(self.image_label)\n",
    "        left.addSpacing(6)\n",
    "        left.addWidget(self.pred_label)\n",
    "\n",
    "        right = QVBoxLayout()\n",
    "        right.addWidget(self.load_model_btn)\n",
    "        right.addWidget(self.load_image_btn)\n",
    "        right.addWidget(self.predict_btn)\n",
    "        right.addSpacing(12)\n",
    "        right.addWidget(QLabel(\"Class probabilities:\"))\n",
    "        right.addWidget(self.prob_list)\n",
    "\n",
    "        top = QHBoxLayout()\n",
    "        top.addLayout(left)\n",
    "        top.addLayout(right)\n",
    "\n",
    "        central = QWidget()\n",
    "        central.setLayout(top)\n",
    "        self.setCentralWidget(central)\n",
    "\n",
    "        self.current_image = None\n",
    "        self.current_image_path = None\n",
    "\n",
    "        # schedule auto-load after event loop starts\n",
    "        QTimer.singleShot(0, self.try_autoload_default_model)\n",
    "\n",
    "    def safe_set_label_text(self, label, text):\n",
    "        try:\n",
    "            label.setText(text)\n",
    "        except RuntimeError as e:\n",
    "            print(\"Warning: widget update failed:\", e)\n",
    "\n",
    "    def try_autoload_default_model(self):\n",
    "        for p in DEFAULT_MODEL_NAMES:\n",
    "            try:\n",
    "                if p.exists():\n",
    "                    self.model_loader.load(p)\n",
    "                    self.safe_set_label_text(self.pred_label, f\"Model loaded from: {p}\\nDevice: {device}\")\n",
    "                    self.predict_btn.setEnabled(True)\n",
    "                    print(\"Auto-loaded model from\", p)\n",
    "                    return\n",
    "            except Exception as e:\n",
    "                print(\"Auto-load failed for\", p, \":\", e)\n",
    "        self.safe_set_label_text(self.pred_label, 'Model not loaded. Click \"Load Model\" to pick model file')\n",
    "\n",
    "    def load_model(self):\n",
    "        path, _ = QFileDialog.getOpenFileName(self, \"Select model file\", str(ARCHIVE_DEFAULT),\n",
    "                                              \"PyTorch model (*.pth *.pt *.h5);;All files (*)\")\n",
    "        if not path:\n",
    "            return\n",
    "        try:\n",
    "            self.model_loader.load(path)\n",
    "            self.safe_set_label_text(self.pred_label, f\"Model loaded from: {path}\\nDevice: {device}\")\n",
    "            self.predict_btn.setEnabled(True)\n",
    "            QMessageBox.information(self, \"Model loaded\", \"Model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            QMessageBox.critical(self, \"Load error\", f\"Failed to load model:\\n{e}\")\n",
    "\n",
    "    def load_image(self):\n",
    "        path, _ = QFileDialog.getOpenFileName(self, \"Select image\", os.getcwd(),\n",
    "                                              \"Images (*.png *.jpg *.jpeg *.bmp);;All files (*)\")\n",
    "        if not path:\n",
    "            return\n",
    "        try:\n",
    "            # when opening the image file\n",
    "            pil_img = Image.open(path)\n",
    "            # force RGB immediately\n",
    "            try:\n",
    "                pil_img = pil_img.convert('RGB')\n",
    "            except Exception:\n",
    "                pil_img = Image.fromarray(np.asarray(pil_img)).convert('RGB')\n",
    "            self.current_image = pil_img\n",
    "            self.current_image_path = path\n",
    "\n",
    "            print(\"Opened image:\", path, \"size:\", pil_img.size, \"mode:\", pil_img.mode)\n",
    "        except Exception as e:\n",
    "            QMessageBox.critical(self, \"Image error\", f\"Unable to open image:\\n{e}\")\n",
    "            print(\"Image open error:\", e)\n",
    "            return\n",
    "        self.current_image = pil_img\n",
    "        self.current_image_path = path\n",
    "\n",
    "        pix = pil_image_to_qpixmap(pil_img, max_size=(520,520))\n",
    "        if pix is None:\n",
    "            QMessageBox.critical(self, \"Display error\", \"Failed to create displayable image. See notebook output.\")\n",
    "            return\n",
    "        self.image_label.setPixmap(pix)\n",
    "        self.safe_set_label_text(self.pred_label, \"Image loaded. Click Predict to run inference.\")\n",
    "        self.predict_btn.setEnabled(self.model_loader.model is not None)\n",
    "\n",
    "    def run_prediction(self):\n",
    "        if self.current_image is None:\n",
    "            QMessageBox.warning(self, \"No image\", \"Please load an image first.\")\n",
    "            return\n",
    "        if self.model_loader.model is None:\n",
    "            QMessageBox.warning(self, \"No model\", \"Please load a model first.\")\n",
    "            return\n",
    "        try:\n",
    "            probs = self.model_loader.predict(self.current_image)\n",
    "        except Exception as e:\n",
    "            QMessageBox.critical(self, \"Inference error\", f\"Model inference failed:\\n{e}\")\n",
    "            print(\"Inference error:\", e)\n",
    "            return\n",
    "\n",
    "        classes = list(self.model_loader.classes) if self.model_loader.classes else DEFAULT_CLASS_NAMES\n",
    "        if len(classes) != len(probs):\n",
    "            classes = [f\"class_{i}\" for i in range(len(probs))]\n",
    "\n",
    "        top_idx = int(np.argmax(probs))\n",
    "        top_name = classes[top_idx]\n",
    "        top_prob = float(probs[top_idx])\n",
    "        self.safe_set_label_text(self.pred_label, f\"Prediction: {top_name} ({top_prob*100:.2f}%)\\nModel device: {device}\")\n",
    "\n",
    "        self.prob_list.clear()\n",
    "        for i,p in enumerate(probs):\n",
    "            item = QListWidgetItem(f\"{classes[i]}: {p*100:.2f}%\")\n",
    "            self.prob_list.addItem(item)\n",
    "\n",
    "\n",
    "# run_app\n",
    "\n",
    "def run_app():\n",
    "    # If running inside Jupyter, enable Qt event loop and avoid exec_()\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        ip = get_ipython()\n",
    "    except Exception:\n",
    "        ip = None\n",
    "\n",
    "    if ip is not None:\n",
    "        # Enable qt event loop for notebook\n",
    "        try:\n",
    "            ip.run_line_magic('gui', 'qt')\n",
    "        except Exception:\n",
    "            pass\n",
    "        app = QApplication.instance()\n",
    "        if app is None:\n",
    "            app = QApplication([])\n",
    "        win = MainWindow()\n",
    "        win.show()\n",
    "        # return handles so user can keep reference in notebook\n",
    "        return win, app\n",
    "    else:\n",
    "        # standard script mode\n",
    "        app = QApplication(sys.argv)\n",
    "        win = MainWindow()\n",
    "        win.show()\n",
    "        sys.exit(app.exec_())\n",
    "\n",
    "win_app = run_app()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfcaaf2-3b12-4085-af3d-cad7eea98b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
